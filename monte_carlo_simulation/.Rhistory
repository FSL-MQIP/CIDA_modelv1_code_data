fitted_param$n0[28] <- summary(b132_buchanan_nls_lm_6_3)$coefficient[1]
fitted_param$lag[28] <- summary(b132_buchanan_nls_lm_6_3)$coefficient[4]
fitted_param$mumax[28] <- summary(b132_buchanan_nls_lm_6_3)$coefficient[3]
fitted_param$nmax[28] <- summary(b132_buchanan_nls_lm_6_3)$coefficient[2]
fitted_param$temp[28] <- "6"
fitted_param$aic[28] <- AIC(b132_buchanan_nls_lm_6_3)
fitted_param$bic[28] <- BIC(b132_buchanan_nls_lm_6_3)
fitted_param$fit[28] <- "no"
fitted_param$method[28] <- "nls_lm"
fitted_param$rep[28] <- "3"
## ---------------------------Packages------------------------------------------
#   Loading packages
library(tidyverse); library(dplyr); library(Metrics)
citation("Metrics")
citation("nlsMicrobio")
setwd("/Volumes/BoorWiedmannLab/ss2633_Sriya_Sunil/Administrative/Papers/Paper1/analyses/2019_isolates")
##--------------------------Packages--------------------------------------------
library(dplyr); library(tidyverse)
##--------------------------Raw Data--------------------------------------------
blast <- read.csv("data/raw/0919a_raw_blast_results.csv", header = TRUE)
metadata <- read.csv("data/raw/FMT_isolates.csv", header = TRUE)
##--------------------------Wrangling-------------------------------------------
top_match <- blast %>%
group_by(qseqid) %>%
arrange(desc(pident)) %>%
slice(1)
top_match$qseqid <- gsub("M9-0544", "M9-0554", top_match$qseqid)
top_match_pruned <- top_match %>%
select(qseqid, subject.titles)
top_match_pruned$qseqid <- gsub("0919a", "", top_match_pruned$qseqid)
metadata_pruned <- metadata %>%
select(FSL, Previous.ID)
fsl_previd <- merge(top_match_pruned, metadata_pruned, by.x = "qseqid", by.y = ("FSL"), all = FALSE)
date <- Sys.Date()
date <- gsub("-", "_", date)
#write.csv(fsl_previd, paste0("data/wrangled/", date, "_0919a_isolates_fsl_previd.csv"), row.names = FALSE)
write.csv(fsl_previd, paste0("data/wrangled/", date, "_0919a_isolates_fsl_previd.csv"), row.names = FALSE)
write.csv(fsl_previd, paste0("data/wrangled/", date, "_0919a_isolates_fsl_previd.csv"), row.names = FALSE)
date <- Sys.Date()
date <- gsub("-", "_", date)
write.csv(fsl_previd, paste0("data/wrangled/", date, "_0919a_isolates_fsl_previd.csv"), row.names = FALSE)
library(tidyverse); library(ggplot2); library(stringi);
data <- read.csv("data/wrangled/2023_03_21_0919a_isolates_fsl_previd.csv", header = TRUE)
data <- data %>%
separate(Previous.ID, c("sampling", "sample_name", "day", "media", "isolate_number"), sep = "-") %>%
separate(subject.titles, c("genus", "species", NA, NA, NA, NA), sep = " ", extra = "drop")
data$day <- stri_replace_all_regex(data$day,
pattern = c("D0", "D4", "D10", "D20"),
replacement = c(0, 4, 10, 20),
vectorize_all = FALSE)
data$day <- factor(data$day, levels = c("0", "4", "10", "20"))
freq <- data.frame(table(data$genus, data$day))
colnames(freq) <- c("genus", "day", "freq")
freq_plot_data <- freq %>%
filter(freq != 0)
freq_table <- table(data$genus, data$day)
#Color plot
ggplot(data = freq_plot_data, mapping = aes(x = day, y = freq, fill = genus, label = freq)) +
geom_col(position = "stack", color = "black") +
theme_classic() + ylab("Number of isolates") + xlab("Day") +
labs(fill = "Genus") + scale_fill_manual(values = c("#AE76A3","#1965B0", "#5289C7", "#1E9F02",
"#CAE0AB", "#F7F056", "#F6C141","#F1932D", "#E8601C",
"#AFADAD")) +
geom_text(position = position_stack(vjust = 0.5))
#Greyscale plot
angle1 <- rep(c(0, 45,45,135), length.out=10)
angle2 <- rep(c(0, 45,135,135), length.out=10)
density1 <- seq(5,20,length.out=10)
density2 <- seq(5,20,length.out=10)
col <- 1
barplot(freq_table, col = col, angle = angle1, density = density1)
barplot(freq_table, col = col, angle = angle2, density = density2)
legend("topright", legend=1:10, ncol =1, fill=TRUE, col=col, angle=angle1, density=density1)
par(bg="transparent")
legend("topright", legend=1:10, ncol =1, fill=TRUE, col=col, angle=angle2, density=density2)
par(op)
date <- Sys.Date()
date <- gsub("-", "_", date)
library(tidyverse); library(ggplot2); library(stringi);
data <- read.csv("data/wrangled/2023_07_09_0919a_isolates_fsl_previd.csv", header = TRUE)
data <- data %>%
separate(Previous.ID, c("sampling", "sample_name", "day", "media", "isolate_number"), sep = "-") %>%
separate(subject.titles, c("genus", "species", NA, NA, NA, NA), sep = " ", extra = "drop")
library(tidyverse); library(ggplot2); library(stringi);
data <- read.csv("data/wrangled/2023_07_09_0919a_isolates_fsl_previd.csv", header = TRUE)
data <- data %>%
separate(Previous.ID, c("sampling", "sample_name", "day", "media", "isolate_number"), sep = "-") %>%
separate(subject.titles, c("genus", "species", NA, NA, NA, NA), sep = " ", extra = "drop")
data$day <- stri_replace_all_regex(data$day,
pattern = c("D0", "D4", "D10", "D20"),
replacement = c(0, 4, 10, 20),
vectorize_all = FALSE)
data$day <- factor(data$day, levels = c("0", "4", "10", "20"))
freq <- data.frame(table(data$genus, data$day))
colnames(freq) <- c("genus", "day", "freq")
freq_plot_data <- freq %>%
filter(freq != 0)
freq_table <- table(data$genus, data$day)
#Color plot
ggplot(data = freq_plot_data, mapping = aes(x = day, y = freq, fill = genus, label = freq)) +
geom_col(position = "stack", color = "black") +
theme_classic() + ylab("Number of isolates") + xlab("Day") +
labs(fill = "Genus") + scale_fill_manual(values = c("#AE76A3","#1965B0", "#5289C7", "#1E9F02",
"#CAE0AB", "#F7F056", "#F6C141","#F1932D", "#E8601C",
"#AFADAD")) +
geom_text(position = position_stack(vjust = 0.5))
#Greyscale plot
angle1 <- rep(c(0, 45,45,135), length.out=10)
angle2 <- rep(c(0, 45,135,135), length.out=10)
density1 <- seq(5,20,length.out=10)
density2 <- seq(5,20,length.out=10)
col <- 1
barplot(freq_table, col = col, angle = angle1, density = density1)
barplot(freq_table, col = col, angle = angle2, density = density2)
legend("topright", legend=1:10, ncol =1, fill=TRUE, col=col, angle=angle1, density=density1)
par(bg="transparent")
legend("topright", legend=1:10, ncol =1, fill=TRUE, col=col, angle=angle2, density=density2)
par(op)
date <- Sys.Date()
date <- gsub("-", "_", date)
png(paste0("outputs/", date, "_microbial_population_over_shelf_life.png"), width = 150, height = 150, units = "mm", res = 1200)
ggplot(data = freq_plot_data, mapping = aes(x = day, y = freq, fill = genus, label = freq)) +
geom_col(position = "stack", color = "black") +
theme_classic() + ylab("Number of isolates") + xlab("Day") +
labs(fill = "Genus") + scale_fill_manual(values = c("#AE76A3","#1965B0", "#5289C7", "#1E9F02",
"#CAE0AB", "#F7F056", "#F6C141","#F1932D", "#E8601C",
"#AFADAD")) +
geom_text(position = position_stack(vjust = 0.5))
dev.off()
library(dplyr); library(tidyverse); library(vegan)
citation("vegan")
data <- read.csv("data/wrangled/2023_03_21_0919a_isolates_fsl_previd.csv", header = TRUE)
at_data <- read.csv("data/raw/16S_AT_assignment.csv", header = TRUE)
at_data <- separate(at_data,
Original_ID,
into = c("sampling", "sample_replicate", "day", "test", "isolate_number"),
sep = "-")
setwd("/Volumes/BoorWiedmannLab/ss2633_Sriya_Sunil/Administrative/Papers/Paper1/analyses/2019_isolates")
data <- read.csv("data/wrangled/2023_03_21_0919a_isolates_fsl_previd.csv", header = TRUE)
data <- read.csv("data/wrangled/2023_03_21_0919a_isolates_fsl_previd.csv", header = TRUE)
data <- read.csv("data/wrangled/2023_07_09_0919a_isolates_fsl_previd.csv", header = TRUE)
data <- data %>%
separate(Previous.ID, c("sampling", "sample_name", "day", "media", "isolate_number"), sep = "-") %>%
separate(subject.titles, c("genus", "species", NA, NA, NA), sep = " ")
at_data <- read.csv("data/raw/16S_AT_assignment.csv", header = TRUE)
at_data <- separate(at_data,
Original_ID,
into = c("sampling", "sample_replicate", "day", "test", "isolate_number"),
sep = "-")
at_data <- at_data %>%
filter(Sequenced.isolates %in% data$qseqid)
#Creating a matrix for assessing alpha-diversity, based on 16S AT
at_table <- as.matrix(table(at_data$day, at_data$AT))
genera_summary <- data.frame(table(data$genus))
other_genera <- genera_summary %>%
filter(Freq < 3) %>%
select(Var1)
other_genera <- as.character(other_genera$Var1)
other_genera <- print(other_genera, quote = FALSE)
data$high_freq_genera <- ifelse(data$genus %in% other_genera, "Other", data$genus)
at_freq_table <- at_data %>%
group_by(AT) %>%
summarize(count = n())
at_table
shannon
shannon <- diversity(at_table, index = "shannon")
shannon
## ---------------------------Packages------------------------------------------
#   Loading packages
library(tidyverse); library(dplyr); library(Metrics)
## ---------------------------Data----------------------------------------------
#   Reading in raw data
model_output <- read.csv("total_count_by_package2023_06_23.csv", header = TRUE)
setwd("/Volumes/BoorWiedmannLab/ss2633_Sriya_Sunil/Research/CIDA_Spinach_Project/Model/shelf_life_model_v1.0.0/output_analysis")
## ---------------------------Packages------------------------------------------
#   Loading packages
library(tidyverse); library(dplyr); library(Metrics)
## ---------------------------Data----------------------------------------------
#   Reading in raw data
model_output <- read.csv("total_count_by_package2023_06_23.csv", header = TRUE)
sampling_data <- read.csv("0919a_microbial_counts_2023_01_27.csv", header = TRUE)
## ---------------------------Checking model output distribution----------------
day <- 1:20
p_val <- vector(mode = "integer", length = length(day))
model_output_shapiro <- data.frame(cbind(day, p_val))
for(i in 1:20){
data <- model_output$total_count[model_output$day == i]
test <- shapiro.test(data)
model_output_shapiro$p_val[model_output_shapiro$day == i] <- test$p.value
}
med_shelf_life <- model_output %>%
group_by(day) %>%
summarize(median = median(total_count))
shelf_life_data <- sampling_data %>%
filter(grepl("D", sample_id)) %>%
filter(!(sample_id %in% c("D", "D0")) & test == "APC")
shelf_life_data$sample_id <- gsub("D", "", shelf_life_data$sample_id)
shelf_life_data$sample_id <- as.numeric(shelf_life_data$sample_id)
med_shelf_life <- med_shelf_life %>%
filter(day %in% shelf_life_data$sample_id)
#Calculating the geometrically averaged mean observation for each day of sampling
shelf_life_data_rmse <-shelf_life_data %>%
mutate(log_conc = log10(average_conc)) %>%
group_by(sampling, sample_id) %>%
summarize(geom_log_conc = mean(log_conc))
rmse_sum <- 0
for(i in 1:nrow(shelf_life_data_rmse)){
d <- shelf_life_data_rmse$sample_id[i]
add <- (med_shelf_life$median[med_shelf_life$day == d] -
shelf_life_data_rmse$geom_log_conc[shelf_life_data_rmse$sample_id == d])^2
rmse_sum <- rmse_sum + add
}
#RMSE
rmse_manual <- sqrt(rmse_sum/nrow(shelf_life_data_rmse))
rmse_manual
rmse_auto <- rmse(shelf_life_data_rmse$geom_log_conc, med_shelf_life$median)
rmse_auto
## ---------------------------Accuracy factor-----------------------------------
#Calculating the geometrically averaged mean observation for each day of sampling
shelf_life_data_af <-shelf_life_data_rmse %>%
mutate(geom_ln_conc = log(geom_log_conc)) %>%
dplyr::select(-geom_log_conc)
med_shelf_life_af <- med_shelf_life %>%
mutate(median_ln = log(median)) %>%
dplyr::select(-median)
af_sum <- 0
for(i in 1:nrow(shelf_life_data_af)){
d <- shelf_life_data_af$sample_id[i]
add <- (med_shelf_life_af$median_ln[med_shelf_life_af$day == d] -
shelf_life_data_af$geom_ln_conc[shelf_life_data_af$sample_id == d])^2
af_sum <- af_sum + add
}
#Accuracy factor
af <- exp(sqrt(af_sum/nrow(shelf_life_data_af)))
percent_discrep <- (af - 1)*100
percent_discrep
percent_discrep
bf_sum <- 0
for(i in 1:nrow(shelf_life_data_af)){
d <- shelf_life_data_af$sample_id[i]
add <- (med_shelf_life_af$median_ln[med_shelf_life_af$day == d] -
shelf_life_data_af$geom_ln_conc[shelf_life_data_af$sample_id == d])
bf_sum <- bf_sum + add
}
#Accuracy factor
bf <- exp(bf_sum/nrow(shelf_life_data_af))
percent_bias <- (-1)*(exp(abs(log(bf))) - 1)*100
percent_bias
af
af
percent_discrep <- (af - 1)*100
percent_discrep
exp(1)
exp(o)
exp(0)
percent_bias
## ---------------------------Packages------------------------------------------
#   Loading packages
library(tidyverse); library(dplyr); library(Metrics)
## ---------------------------Data----------------------------------------------
#   Reading in raw data
model_output <- read.csv("total_count_by_package.csv", header = TRUE)
sampling_data <- read.csv("0919a_microbial_counts.csv", header = TRUE)
packages_summary <- read.csv("packages_summary.csv", header = TRUE)
## ---------------------------Checking model output distribution----------------
day <- 1:20
p_val <- vector(mode = "integer", length = length(day))
model_output_shapiro <- data.frame(cbind(day, p_val))
for(i in 1:20){
data <- model_output$total_count[model_output$day == i]
test <- shapiro.test(data)
model_output_shapiro$p_val[model_output_shapiro$day == i] <- test$p.value
}
med_shelf_life <- model_output %>%
group_by(day) %>%
summarize(median = median(total_count))
shelf_life_data <- sampling_data %>%
filter(grepl("D", sample_id)) %>%
filter(!(sample_id %in% c("D", "D0")) & test == "APC")
shelf_life_data$sample_id <- gsub("D", "", shelf_life_data$sample_id)
shelf_life_data$sample_id <- as.numeric(shelf_life_data$sample_id)
med_shelf_life <- med_shelf_life %>%
filter(day %in% shelf_life_data$sample_id)
#Calculating the geometrically averaged mean observation for each day of sampling
shelf_life_data_rmse <-shelf_life_data %>%
mutate(log_conc = log10(average_conc)) %>%
group_by(sampling, sample_id) %>%
summarize(geom_log_conc = mean(log_conc))
rmse_auto <- rmse(shelf_life_data_rmse$geom_log_conc, med_shelf_life$median)
rmse_auto
## ---------------------------Accuracy factor-----------------------------------
#Calculating the geometrically averaged mean observation for each day of sampling
shelf_life_data_af <-shelf_life_data_rmse %>%
mutate(geom_ln_conc = log(geom_log_conc)) %>%
dplyr::select(-geom_log_conc)
med_shelf_life_af <- med_shelf_life %>%
mutate(median_ln = log(median)) %>%
dplyr::select(-median)
af_sum <- 0
for(i in 1:nrow(shelf_life_data_af)){
d <- shelf_life_data_af$sample_id[i]
add <- (med_shelf_life_af$median_ln[med_shelf_life_af$day == d] -
shelf_life_data_af$geom_ln_conc[shelf_life_data_af$sample_id == d])^2
af_sum <- af_sum + add
}
#Accuracy factor
af <- exp(sqrt(af_sum/nrow(shelf_life_data_af)))
percent_discrep <- (af - 1)*100
percent_discrep
bf_sum <- 0
for(i in 1:nrow(shelf_life_data_af)){
d <- shelf_life_data_af$sample_id[i]
add <- (med_shelf_life_af$median_ln[med_shelf_life_af$day == d] -
shelf_life_data_af$geom_ln_conc[shelf_life_data_af$sample_id == d])
bf_sum <- bf_sum + add
}
#Bias factor
bf <- exp(bf_sum/nrow(shelf_life_data_af))
percent_bias <- (-1)*(exp(abs(log(bf))) - 1)*100
percent_bias
d18_summary <- packages_summary %>%
filter(day == "18") %>%
mutate(abov_thresh = ifelse(total_count > 8.0, "y", "n"))
View(d18_summary)
View(packages_summary)
setwd("/Volumes/BoorWiedmannLab/ss2633_Sriya_Sunil/Administrative/Papers/Paper1_cida_model_v1/analyses/github_data_code/CIDA_modelv1_code_data/monte_carlo_simulation")
#   Loading packages
library(dplyr); library(MASS); library(VGAM)
#Set seed
set.seed(1)
strain_param <- read.csv("model_inputs/primary_model_parameters_strain_averaged.csv", header = TRUE)
mumax_secon <- read.csv("model_inputs/secondary_model_mumax_strain_averaged.csv", header = TRUE)
st_frequency <- read.csv("model_inputs/st_frequency.csv", header = TRUE)
initial_count <- read.csv("model_inputs/initial_distribution.csv", header = TRUE)
#Change strain parameters to lowercase
strain_param$isolate <- tolower(strain_param$isolate)
mumax_secon$isolate <- tolower(mumax_secon$isolate)
#Change the formatting of a variable in the ST frequency
st_frequency$growth_isolates <- substr(st_frequency$growth_isolates, 1, 8)
st_frequency$growth_isolates <- tolower(st_frequency$growth_isolates)
#Initial Count Distribution: Log transforming initial count, and fitting a uniform distribution to the data
initial_count_dist <- function(n){
ans <- runif(n, min = initial_count$min, max = initial_count$max)
return(ans)
}
#ST Distribution
isolates <- st_frequency$growth_isolates
st_prev <- st_frequency$frequency
st_dist <- function(n) {
ans <- sample(isolates, size = n, prob = st_prev, replace = F)
return(ans)
}
#Storage Temperature Distribution
temp_location <- 4.06
temp_shape <- 2.31
temp_dist <- function(n) {
ans <- rlaplace(n, temp_location, temp_shape)
for(i in 1:n)
while (ans[i] < 2 | ans[i] > 14) {
ans[i] <- rlaplace(1, temp_location, temp_shape)
}
return(ans)
}
pop_dist <- function(n){
ans <- runif(n, min = 1, max = 6)
ans_rounded <- round(ans, digits = 0)
return(ans_rounded)
}
#Primary Growth Models
#Gompertz
gompertz <- function(day, log10n0, log10nmax, mumax, lag){
log10n <- log10n0 + (log10n0 < log10nmax)*(log10nmax - log10n0) * exp(-exp(mumax * exp(1) * (lag - day) / ((log10nmax - log10n0) * log(10)) + 1))
}
#Mumax
NewMu_general <- function(temp, b, temp_min){
if(temp > temp_min){
sqrt_mu <- b*(temp - temp_min)
ans <- sqrt_mu^2
return(ans)
} else {
ans <- 0
return(ans)
}
}
NewMu_s12_0141 <- function(temp, b, temp_min){
if(temp < temp_min){
sqrt_mu <- b*(temp - temp_min)
ans <- sqrt_mu^2
return(ans)
} else {
ans <- 0
return(ans)
}
}
NewMu <- function(temp, b, temp_min, isolate){
if(isolate != "s12-0141"){
return(NewMu_general(temp, b, temp_min))
} else {
return(NewMu_s12_0141(temp, b, temp_min))
}
}
lag_tmin <- mumax_secon$temp_min_mu[mumax_secon$isolate == "s12-0116"]
NewLag <- function(temp, lag) {
ans <- lag*((6 - lag_tmin)/(temp - lag_tmin))^2
return(ans)
}
n_lots <- 1
n_packages <- 1000
n_sim <- n_packages*n_lots
n_day <- 22
#Assigning initial count, number of strains, STs and temperature to each package
packages_sim <- data.frame(matrix(nrow = n_sim, ncol = 4))
colnames(packages_sim) <- c("package", "initial_count_apc", "storage_temp", "tot_strains")
packages_sim$package <- 1:n_packages
packages_sim$initial_count_apc <- initial_count_dist(n_sim)
packages_sim$storage_temp <- temp_dist(n_sim)
packages_sim$tot_strains <- pop_dist(n_sim)
#Expanding the dataframe to store observations for each strain and day of observation
packages_sim_exp <- packages_sim %>%
group_by(package) %>%
slice(rep(1, times = tot_strains)) %>%
mutate(isolate = NA, initial_count = NA, lag = NA, mumax = NA, nmax = NA)
#Assigning isolates to each package, with replacement
for(i in 1:n_packages){
index <- which(packages_sim_exp$package == i)
strain_per_package <- unique(packages_sim_exp$tot_strains[index])
packages_sim_exp$isolate[index] <- st_dist(strain_per_package)
packages_sim_exp$initial_count[index] <- rep(log10((10^(packages_sim$initial_count_apc[i]))/strain_per_package), times = strain_per_package)
}
#Assign lag to each package
for(i in 1:nrow(packages_sim_exp)){
strain_index <- which(packages_sim_exp$isolate[i] == strain_param$isolate & 6 == strain_param$temp)
strain_lag <- NewLag(packages_sim_exp$storage_temp[i], strain_param$lag[strain_index])
packages_sim_exp$lag[i] <- strain_lag
}
#Assign mumax to each package
for(i in 1:nrow(packages_sim_exp)){
strain_index <- which(packages_sim_exp$isolate[i] == mumax_secon$isolate)
strain_mu <- NewMu(packages_sim_exp$storage_temp[i], mumax_secon$b_mu[strain_index], mumax_secon$temp_min_mu[strain_index], packages_sim_exp$isolate[i])
packages_sim_exp$mumax[i] <- strain_mu
}
#Assign nmax to each package
for(i in 1:nrow(packages_sim_exp)){
strain_index <- which(packages_sim_exp$isolate[i] == strain_param$isolate & strain_param$temp == 6)
strain_nmax <- strain_param$nmax[strain_index]
packages_sim_exp$nmax[i] <- strain_nmax
}
#Calculate the total nmax of a package
packages_sim_exp$final_nmax <- vector(mode = "integer", length = nrow(packages_sim_exp))
for(i in 1:n_packages){
index <- which(packages_sim_exp$package == i)
packages_nmax <- packages_sim_exp$nmax[index]
final_nmax <- log10(sum(10^packages_nmax))
packages_sim_exp$final_nmax[index] <- final_nmax
}
#Creating a dataframe, to assess microbial growth over shelf life
shelf_life_sim <- packages_sim_exp %>%
group_by(package, isolate) %>%
slice(rep(1, times = 22)) %>%
mutate(day = 1:22)
shelf_life_sim <- shelf_life_sim %>%
mutate(count = gompertz(day, initial_count, nmax, mumax, lag))
day18_sim_output <- shelf_life_sim %>%
filter(day == 18) %>%
group_by(package) %>%
summarize(total_count = log10(sum(10^(count))))
d18_spoiled <- day18_sim_output %>%
summarize(spoiled = sum(total_count > 8.0)/n_packages)
h18 <- hist(day18_sim_output$total_count,
breaks = 15,
xlab = "Bacterial concentration, log10(CFU/g)",
ylab = "Density", main = "Simulation without secondary model for lag",
prob = TRUE, col = "white")
abline(v = 8.0, lty = 4)
legend(
'topleft', ncol = 1,
legend = c(
'Percent of packages spoiled on Day 18',  (d18_spoiled$spoiled*100)))
percent_packages_nmax <- shelf_life_sim %>%
group_by(day, package) %>%
mutate(total_count = log10(sum(10^(count)))) %>%
slice(1) %>%
mutate(at_nmax = round(final_nmax, 1)  == round(total_count, 1)) %>%
group_by(day) %>%
summarize(percent_packs_nmax = (sum(at_nmax == TRUE)/n_packages)*100)
mode <- function(x) {
t <- table(x)
names(t)[ which.max(t) ]
}
count_summary_by_day <- shelf_life_sim %>%
group_by(day, package) %>%
summarize(total_count = log10(sum(10^(count)))) %>%
mutate(rounded_total_count = round(total_count, 1)) %>%
group_by(day) %>%
summarize(mean = mean(total_count),
sd_total_count = sd(total_count),
mode = mode(rounded_total_count),
median = median(total_count))
counts_summary_by_package <- shelf_life_sim %>%
group_by(day, package) %>%
summarize(total_count = log10(sum(10^(count))))
package_summary <- shelf_life_sim %>%
group_by(day, package) %>%
mutate(total_count = log10(sum(10^(count))),
mean_mumax = mean(mumax),
mean_lag = mean(lag)) %>%
dplyr::select(-c("count", "nmax", "mumax", "initial_count",
"isolate", "lag")) %>%
ungroup() %>%
group_by(day, package) %>%
slice(1)
View(package_summary)
